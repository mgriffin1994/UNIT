import matplotlib.pyplot as pltimport scipyfrom scipy import signalfrom scipy.io import wavfileimport numpy as npfrom scipy.signal import stft, istftfrom array import arrayimport osimport sysfrom time import time"""This moduel generates dataset of images from .wav fileDirectory of saved file: **/IRMAS-TrainingData/&&/spec_data/image_with_params                            where ** denotes dir where IRMAS-TrainingData folder is stored                                    && denotes sub-directory of IRMAS-TrainingData, say, &&='flu'Format of calling this module from terminal: python3 dataset_gen.py **/IRMAS-TrainingData/&& mode                                where mode = 'mag+phase' or 'mag', the former creates matrix of both magnitude and phase;                                              the later only creates matrix of magnitude                                        if mode is not specified, default mode is 'mag+phase'Calling function dataset_gen(...) in this module is equiv. to calling the whole moduleFormat of saved .npz file:         data = np.load(filename), then type(data) = dictionary and        data = {'true_spec_shape': a tuple (not used, ignore it), 'spec4train': matrix of an image,                 'nperseg': a real number, 'nfft': a real number, 'sample_rate': a real number                'mode': str, 'num_channel': an integer}Format of matrix data:  M.shape = (#pixel-yaxis, #pixel-xaxis, z),                         (mono-channel audio) + (mode=='mag_only'):   z = 1                        (mono-channel audio) + (mode=='mag+phase'):  z = 2,  M[:,:,0] = magnitude,M[:,:,1] = phase                         (stereo audio) + (mode=='mag_only'): z = 2,  M[:,:,0] = magnitude of channel 1,                                                                             M[:,:,1] = magnitude of channel 2,                        (stereo audio) + (mode=='mag+phase'): z = 4, M[:,:,0] = magnitude of channel 1,                                                                             M[:,:,1] = phase of channel 1,                                                                             M[:,:,2] = magnitude of channel 2,                                                                              M[:,:,0] = phase of channel 3,""" # def rename(path):#     if "IRMAS-TrainingData" not in path:#         raise(ValueError("correct directory shoule contain 'IRMAS-TrainingData' "))#     file_list = os.listdir(path)#     path = path+'/'#     pt = 0#     length = length(file_list)#     for l in range(length):#         new_name = str(l)+'.wav'#         if new_name in file_list:#             continue#         while pt < length:#             temp = file_list[pt]#             pt = pt + 1#             if new_name < temp and ('.wav' is in temp):#                 os.rename(path+temp, path+new_name)#                 breakdef rename(path):    if ("IRMAS-TrainingData" not in path) and ("vcc2016_training" not in path):        raise(ValueError("correct directory shoule contain 'IRMAS-TrainingData' "))    file_list = os.listdir(path)    path = path+'/'    k = 0    for old_name in file_list:        if '.wav' in old_name:            k = k+1            os.rename(path+old_name, path+'***'+'.temp'+str(k)+'.wav')    k = 0           file_list = os.listdir(path)       for old_name in file_list:        if '.wav' in old_name:            k = k+1            os.rename(path+old_name, path+str(k)+'.wav')    def crop(M, obj_shape, varname, num_image_per_audio=3):    xobj, yobj = obj_shape[1], obj_shape[0]    xm, ym = M.shape[1], M.shape[0]    num_crop = int(np.ceil(xm/xobj))    assert (num_crop == num_image_per_audio)        temp = len(M.shape)    if temp == 2:        num_img_ch = 1        # print("shape of M before: ", M.shape)        M = np.reshape(M, (ym,xm,1))        # print("shape of M after: ", M.shape)    elif temp == 3:        num_img_ch = M.shape[2]    else:        print("shape of input: ", M.shape)        raise(ValueError("wrong dimension"))        dic = {}        for k in range(num_crop-1):        temp = M[0:yobj,k*xobj:(k+1)*xobj,:]        dic[varname+str(k)] = temp            temp = M[0:yobj, (num_crop-1)*xobj:num_crop*xobj, :]    last_img = shape_patch_3D(temp, obj_shape)    dic[varname+str(num_crop-1)] = last_img    return dic    # def test_crop():#     M = np.random.rand(5,4)#     obj_shape = (2,3,1)#     a = crop(M, obj_shape, num_image_per_audio=2)#     print(a)#     print()#     print(M)#     print()#     print( np.reshape(a['M_crop1'],(2,3)) )def shape_patch_3D(M, obj_shape):    # shape patch M to M'.shape = obj_shape    xm = M.shape[1]    xobj = obj_shape[1]    if xm < xobj:        M_patched = np.empty((obj_shape[0],xobj,obj_shape[2]), dtype='complex64')        M_patched[:,0:xm,:] = M        dl = xobj - xm        last_col = M[:,-1,:]          for k in range(dl):            M_patched[:,xm+k,:] =  last_col            # print(temp2)    elif xm > xobj:           M_patched = M[:, 0:xobj,:]    elif xm == xobj:        M_patched = M    return M_patcheddef shape_patch(M, obj_shape):    # shape patch M to M'.shape = obj_shape    xm = M.shape[1]    xobj = obj_shape[1]    if xm < xobj:        M_patched = np.zeros((obj_shape[0],xobj), dtype='complex64')        M_patched[:,0:xm] = M        dl = xobj - xm        last_col = M[:,-1]          # print(temp)        for k in range(dl):            M_patched[:,xm+k] =  last_col            # print(temp2)    elif xm > xobj:           M_patched = M[:, 0:xobj]    elif xm == xobj:        M_patched = M    return M_patched    def audio2spec_core(samples, sample_rate, num_pixel_x=512, num_pixel_y=2048):      # note: num_pixel_x and num_pixel_y here are resolutions before cropping    # process one channel only    num_samples = len(samples)      ovlp_rate = 0;        temp = num_pixel_x - int(np.floor( (num_pixel_x-1)*ovlp_rate ))    nperseg = int(np.floor( num_samples/temp ))    nfft = num_pixel_y*2 - 1    noverlap = int(nperseg*ovlp_rate)    num_samples = nperseg*(num_pixel_x- int(np.floor( ovlp_rate*(num_pixel_x-1) )) )    # print("updated num_samples******************", num_samples)    # print("nperseg ******************", nperseg)    # print("noverlap ******************", noverlap)    # print("nfft ******************", nfft)    samples = samples[0:num_samples]           frequencies, times, true_spec = \        stft(samples, fs=sample_rate, window='boxcar', noverlap=noverlap, nperseg = nperseg,nfft=nfft)    # frequencies, times, spec = signal.spectrogram(samples, fs = sample_rate, window = 'hann', nperseg = 160, nfft=512, scaling = 'density',mode = 'complex')    # num_row = np.int(np.floor( spec.shape[1]/2 ))    obj_shape = (num_pixel_y, num_pixel_x)    spec4train = shape_patch(true_spec, obj_shape)    # print("shape*********", spec4train.shape)    assert (spec4train.shape[1] == num_pixel_x) and (spec4train.shape[0] == num_pixel_y)        params = {'sample_rate':sample_rate, 'nfft':nfft, 'nperseg':nperseg, 'noverlap':noverlap}    return true_spec.shape, spec4train, times, frequencies, params    def audio2spec_per_image(samples, sample_rate, num_pixel_x=512, num_pixel_y=512):    # for mono channel audio    num_samples = len(samples)    true_shape, spec4train, times, freqs, params = \        audio2spec_core(samples, sample_rate, num_pixel_x=num_pixel_x, num_pixel_y=num_pixel_y)         return true_shape, spec4train, times, freqs, paramsdef double_ch_audio2spec_per_image(samples, sample_rate, num_pixel_x=512, num_pixel_y=512):    samples0 = samples[:,0]    samples1 = samples[:,1]    num_samples = len(samples0)    t0 = time()    true_shape, spec4train0, times, freqs, params = \        audio2spec_core(samples0, sample_rate, num_pixel_x=num_pixel_x, num_pixel_y=num_pixel_y)    true_shape, spec4train1, times, freqs, params = \        audio2spec_core(samples1, sample_rate, num_pixel_x=num_pixel_x, num_pixel_y=num_pixel_y)    # t1 = time()    # dt = t1-t0    # print("time used to convert one audio, total #samples **************", dt, 2*len(samples0))    t0 = time()       spec4train = np.stack([spec4train0, spec4train1], axis=2)    t1 = time()    dt = t1-t0    # print("time used to stack", dt)    return true_shape, spec4train, times, freqs, params     def down_sample(sample_rate, samples, dwsamp_rate):        sample_rate = int(sample_rate/dwsamp_rate)    if len(samples.shape) == 1:        samples = samples[0:-1:dwsamp_rate]    elif len(samples.shape) == 2:        samples = samples[0:-1:dwsamp_rate, :]    else:        raise(TypeError("wrong type of samples"))    return sample_rate, samples    def dataset_gen(audio_dir, mode = "mag_only", dwsamp_freq=44100, crop_freq=22050, num_image_per_audio=1, pixelx=512, pixely=512, ovrite=1):    # ovrite: 1: compute spectrogram and overwrite existing image data if exsits    #         0: do not ovrite exsiting image data, compute and visualize the spectrodiram of the first .wav file    # mode: "mag_only" or "mag+phase"    # max_freq: max frequency of audio's spectrogram    if dwsamp_freq < crop_freq*2:        raise ValueError("dwsamp_freq should be greater than crop_freq!")            rename(audio_dir)    prfx = audio_dir + '/'    sufx = ".wav"    output_dir = prfx + "spec_data/"    prfx_out = "pic_"    input_filename = prfx+ str(1)+ sufx      sample_rate, samples = wavfile.read(input_filename)        dwsamp_rate = int(np.floor(sample_rate/dwsamp_freq));    # dwsamp_rate = 1    sample_rate, samples = down_sample(sample_rate, samples, dwsamp_rate)    print("after down sampling: sample_rate, #samples, dwsamp_rate = ", sample_rate, samples.shape[0], dwsamp_rate)        px = pixelx*num_image_per_audio    py = pixely*int(np.floor(sample_rate/2/crop_freq))    t0=time()     try:        num_ch = samples.shape[1]    except(IndexError):        num_ch = 1    print("number of channels: ", num_ch)        if num_ch == 1:        true_spec_shape, spec4train, times, frequencies, params= \            audio2spec_per_image(samples, sample_rate, num_pixel_x=px, num_pixel_y=py)              if num_ch == 2:        true_spec_shape, spec4train, times, frequencies, params= \            double_ch_audio2spec_per_image(samples, sample_rate, num_pixel_x=px, num_pixel_y=py)    if len(times) < px:        dl = px - len(times)        for k in range(dl):            times = np.append(times, times[-1]*2-times[-2])    else:         times = times[0:px]    t1=time()    print("****************time cost of fist conversion ****************", t1-t0)         print("**************** first convertion completed! *****************")#***************************** visualizing spectrogram of first audio ******************************                  # plt.plot(times)    # plt.show()    # print("shape of spec4train:****************", spec4train.shape)    try:        temp = spec4train[:,:,0]    except:        temp = spec4train    sp = np.reshape(temp, -1, 1)    sp = np.squeeze(sp);    plt.figure()    plt.title("spectrum of first audio, before cropping, suqeezed to 1-D")    plt.ylabel("Magnitude")    plt.xlabel("#points")    plt.plot(np.abs(sp))    plt.show()        if num_ch == 1:          plt.figure()        plt.pcolormesh(times[0:px], frequencies[0:py], np.abs(spec4train)/np.amax(np.abs(spec4train)), cmap = "spring", vmax=1)        plt.ylabel('Frequency [Hz]')        plt.xlabel('Time [sec]')        plt.title("spectrogram of first audio, before cropping, mono-channel")        plt.show()    if num_ch == 2:        plt.figure()        plt.pcolormesh(times[0:px], frequencies[0:py], np.abs(spec4train[:,:,0])/np.amax(np.abs(spec4train[:,:,0])), cmap = "spring", vmax=1)        plt.ylabel('Frequency [Hz]')        plt.xlabel('Time [sec]')        plt.title("spectrogram of first audio, before cropping, left channel")        plt.show()                plt.figure()        plt.pcolormesh(times[0:px], frequencies[0:py], np.abs(spec4train[:,:,1])/np.amax(np.abs(spec4train[:,:,1])), cmap = "spring", vmax=1)        plt.ylabel('Frequency [Hz]')        plt.xlabel('Time [sec]')        plt.title("spectrogram of first audio, before cropping, right channel")        plt.show()    # plt.imshow(abs(spec4train)/np.amax(np.abs(spec4train)),cmap = "cool", vmax = 1)    #********************************* generate and save spectrograms to file  *********************************    k = 0    s = 0    while True:        if ovrite == "0" or (not ovrite):            break        k = k+1        input_filename = prfx+ str(k)+ sufx        try:            # print('*******************'+input_filename)            sample_rate, samples = wavfile.read(input_filename)            sample_rate, samples = down_sample(sample_rate, samples, dwsamp_rate)        except FileNotFoundError:            break        if num_ch == 1: # only one channel            true_spec_shape, spec4train, times, frequencies, params = \                audio2spec_per_image(samples, sample_rate, num_pixel_x=px, num_pixel_y=py)            spec4train = np.reshape(spec4train, (spec4train.shape[0], spec4train.shape[1], -1))            spec4train = spec4train[0:pixely,:,:]            mag = np.abs(spec4train)/np.amax(np.abs(spec4train))*255;            temp = np.angle(spec4train, deg=True)            # print("******* max phase ********", np.amax(temp))            phase = (temp+180)/360*255            if mode == "mag_only":                 spec4train = mag            elif mode == "mag+phase":                spec4train = np.stack([mag[:,:,0], phase[:,:,0]], axis=2)            else:                raise(ValueError("Opps! Wrong input."))                        elif num_ch == 2: # two channels            # t0 = time()            true_spec_shape, spec4train, times, frequencies, params = \                double_ch_audio2spec_per_image(samples, sample_rate, num_pixel_x=px, num_pixel_y=py)            # t1 = time()            # print("converstion time per audio:", t1-t0)            spec4train = spec4train[0:pixely,:,:]            mag = np.abs(spec4train)/np.amax(np.abs(spec4train))*255;            temp = np.angle(spec4train, deg=True)            phase = (temp+180)/360*255            if mode == "mag_only":                spec4train = mag            elif mode == "mag+phase":                # print("mag shape =", mag.shape)                spec4train = np.stack( (mag[:,:,0], phase[:,:,0], mag[:,:,1], phase[:,:,1]), axis=2)            else:                raise(ValueError("Opps! Wrong input."))          else:            raise(ValueError("Opps! Wrong number of channels."))                    spec4train_dict = crop(spec4train, (pixely, pixelx), "spec4train", num_image_per_audio=num_image_per_audio)        assert num_image_per_audio == len(spec4train_dict)                # ********** save data:        for t in range(num_image_per_audio):            s = s+1            spec4train = np.array(spec4train_dict['spec4train'+str(t)], dtype='float32')                  filename = output_dir + "/image_with_params/" + prfx_out + str(s) +'.npz'              if k == 1:                os.makedirs(os.path.dirname(filename), exist_ok=True)            with open(filename, "wb") as f:                np.savez(f, true_spec_shape=true_spec_shape, spec4train=spec4train, nperseg=params['nperseg'], \                    noverlap=params['noverlap'],nfft=params['nfft'], sample_rate=params['sample_rate'], mode=mode, num_channel=num_ch)                if k <= 50 and not(k%5):            print()            print(input_filename)            print("nperseg ******************", params['nperseg'])            print("noverlap ******************", params['noverlap'])            print("nfft ******************", 2*pixely-1)            print("sample_rate ******************", params['sample_rate'])            print("number of samples per channel *****************", samples.shape[0])#********************************* visualizing spectrogram from loaded file *********************************    print("visualizing spectrogram from one loaded file:")    filename = output_dir + "/image_with_params/" + prfx_out + str(1) + '.npz'    data = np.load(filename)    spec4train = data['spec4train']        if mode == "mag+phase":        plt.figure()        sp_phase = np.reshape(spec4train[:,:,1], -1, 1)        plt.plot(sp_phase)        plt.title("Loaded from dataset (one image), squeezed to 1-D")        plt.ylabel("phase [deg]")        plt.show()        print("shape of spectrum *****", spec4train.shape)        sp = np.reshape(spec4train[:,:,0], -1, 1)        sp = np.squeeze(sp);        plt.figure()        plt.plot(np.abs(sp))        plt.title("Loaded from dataset (first channel), squeezed to 1-D")        plt.ylabel('magnitude')        plt.show()            # if num_ch == 1:  #       plt.figure()  #       print(spec4train.shape)  #       plt.pcolormesh(times[0:px], frequencies[0:spec4train.shape[0]], np.abs(spec4train)/np.amax(np.abs(spec4train)), cmap = "spring", vmax=1)  #       plt.ylabel('Frequency [Hz]')  #       plt.xlabel('Time [sec]')  #       plt.title("spectrogram of first audio, bloaded from dataset, mono-channel")  #       plt.show()    if num_ch == 2:        plt.figure()        plt.pcolormesh(times[0:px], frequencies[0:spec4train.shape[0]], np.abs(spec4train[:,:,0])/np.amax(np.abs(spec4train[:,:,0])), cmap = "spring", vmax=1)        plt.ylabel('Frequency [Hz]')        plt.xlabel('Time [sec]')        plt.title("spectrogram of first audio, loaded from dataset, left channel")        plt.show()                plt.figure()        plt.pcolormesh(times[0:px], frequencies[0:spec4train.shape[0]], np.abs(spec4train[:,:,2])/np.amax(np.abs(spec4train[:,:,2])), cmap = "spring", vmax=1)        plt.ylabel('Frequency [Hz]')        plt.xlabel('Time [sec]')        plt.title("spectrogram of first audio, loaded from dataset, right channel")        plt.show()        if __name__ == "__main__":    # calling format: python3 dataset_gen.py /Volumes/Mac_Ext/dataset/IRMAS-TrainingData/flu 'mag+phase'    # python3 dataset_gen.py "/Volumes/Mac_Ext/dataset/vcc2016_training/SF1" 'mag+phase'    audio_dir = sys.argv[1]    if len(sys.argv) < 3:        mode = "mag+phase"    else:        mode = sys.argv[2]    dataset_gen(audio_dir, mode="mag+phase", dwsamp_freq=16000, crop_freq=4000, num_image_per_audio=1, pixelx=256, pixely=256, ovrite=1)                         